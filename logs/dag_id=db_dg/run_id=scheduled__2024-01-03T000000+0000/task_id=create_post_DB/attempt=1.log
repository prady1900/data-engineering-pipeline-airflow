[2024-01-04T07:00:44.809+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: db_dg.create_post_DB scheduled__2024-01-03T00:00:00+00:00 [queued]>
[2024-01-04T07:00:44.846+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: db_dg.create_post_DB scheduled__2024-01-03T00:00:00+00:00 [queued]>
[2024-01-04T07:00:44.848+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 3
[2024-01-04T07:00:44.979+0000] {taskinstance.py:2192} INFO - Executing <Task(PostgresOperator): create_post_DB> on 2024-01-03 00:00:00+00:00
[2024-01-04T07:00:44.983+0000] {standard_task_runner.py:60} INFO - Started process 350 to run task
[2024-01-04T07:00:44.986+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'db_dg', 'create_post_DB', 'scheduled__2024-01-03T00:00:00+00:00', '--job-id', '60', '--raw', '--subdir', 'DAGS_FOLDER/create_database_dag.py', '--cfg-path', '/tmp/tmp_vr28bve']
[2024-01-04T07:00:44.989+0000] {standard_task_runner.py:88} INFO - Job 60: Subtask create_post_DB
[2024-01-04T07:00:45.262+0000] {task_command.py:423} INFO - Running <TaskInstance: db_dg.create_post_DB scheduled__2024-01-03T00:00:00+00:00 [running]> on host 34fb0f920c20
[2024-01-04T07:00:45.631+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='prady1900' AIRFLOW_CTX_DAG_ID='db_dg' AIRFLOW_CTX_TASK_ID='create_post_DB' AIRFLOW_CTX_EXECUTION_DATE='2024-01-03T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-03T00:00:00+00:00'
[2024-01-04T07:00:45.633+0000] {sql.py:276} INFO - Executing: 
create table if not exists incident_new(
    id integer primary_key,
    impact integer,
    number varchar(50)
)
[2024-01-04T07:00:45.645+0000] {base.py:83} INFO - Using connection ID 'postgres_connect' for task execution.
[2024-01-04T07:00:45.820+0000] {base.py:83} INFO - Using connection ID 'postgres_connect' for task execution.
[2024-01-04T07:00:45.891+0000] {taskinstance.py:2699} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/operators/sql.py", line 282, in execute
    output = hook.run(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/hooks/sql.py", line 385, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/postgres/hooks/postgres.py", line 158, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "host.docker.local" to address: Name or service not known

[2024-01-04T07:00:45.912+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=db_dg, task_id=create_post_DB, execution_date=20240103T000000, start_date=20240104T070044, end_date=20240104T070045
[2024-01-04T07:00:46.119+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 60 for task create_post_DB (could not translate host name "host.docker.local" to address: Name or service not known
; 350)
[2024-01-04T07:00:46.163+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-01-04T07:00:46.202+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-01-04T13:45:58.158+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: db_dg.create_post_DB scheduled__2024-01-03T00:00:00+00:00 [queued]>
[2024-01-04T13:45:58.190+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: db_dg.create_post_DB scheduled__2024-01-03T00:00:00+00:00 [queued]>
[2024-01-04T13:45:58.191+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 3
[2024-01-04T13:45:58.287+0000] {taskinstance.py:2192} INFO - Executing <Task(PostgresOperator): create_post_DB> on 2024-01-03 00:00:00+00:00
[2024-01-04T13:45:58.291+0000] {standard_task_runner.py:60} INFO - Started process 667 to run task
[2024-01-04T13:45:58.294+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'db_dg', 'create_post_DB', 'scheduled__2024-01-03T00:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/create_database_dag.py', '--cfg-path', '/tmp/tmpgstt8dgr']
[2024-01-04T13:45:58.296+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask create_post_DB
[2024-01-04T13:45:58.452+0000] {task_command.py:423} INFO - Running <TaskInstance: db_dg.create_post_DB scheduled__2024-01-03T00:00:00+00:00 [running]> on host 4a92eecc6669
[2024-01-04T13:45:58.655+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='prady1900' AIRFLOW_CTX_DAG_ID='db_dg' AIRFLOW_CTX_TASK_ID='create_post_DB' AIRFLOW_CTX_EXECUTION_DATE='2024-01-03T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-03T00:00:00+00:00'
[2024-01-04T13:45:58.656+0000] {sql.py:276} INFO - Executing: 
create table if not exists incident_new(
    id serial ,
    impact integer,
    number varchar(50),
    severity integer,
    priority integer,
    assignment_group varchar(40),
    resolve_time integer,
    category varchar(50),
    primary key(id)
)
[2024-01-04T13:45:58.675+0000] {base.py:83} INFO - Using connection ID 'postgres_connect' for task execution.
[2024-01-04T13:45:58.747+0000] {base.py:83} INFO - Using connection ID 'postgres_connect' for task execution.
[2024-01-04T13:45:58.765+0000] {sql.py:432} INFO - Running statement: 
create table if not exists incident_new(
    id serial ,
    impact integer,
    number varchar(50),
    severity integer,
    priority integer,
    assignment_group varchar(40),
    resolve_time integer,
    category varchar(50),
    primary key(id)
), parameters: None
[2024-01-04T13:45:58.784+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=db_dg, task_id=create_post_DB, execution_date=20240103T000000, start_date=20240104T134558, end_date=20240104T134558
[2024-01-04T13:45:58.868+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-01-04T13:45:58.896+0000] {taskinstance.py:3281} INFO - 1 downstream tasks scheduled from follow-on schedule check
